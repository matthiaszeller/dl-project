{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:ml] *",
      "language": "python",
      "name": "conda-env-ml-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Auxiliary-loss.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b27f7KUWOvEn"
      },
      "source": [
        "# Paper *Self-Supervised Generalisation with Meta Auxiliary Learning*\n",
        "\n",
        "https://papers.nips.cc/paper/2019/file/92262bf907af914b95a0fc33c3f33bf6-Paper.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "berrgfqfOvEw"
      },
      "source": [
        "Using an auxiliary loss is called auxiliary learning, and is similar to multi-task learning, except that only the primary task is of interest. In our case, the primary task is to output whether image 1 is a digit smaller than image 2. The role of the auxiliary task is to assist in generalization of this primary task.\n",
        "\n",
        "This paper discusses unsupervised auxiliary learning, for the cases when no label exist for the auxiliary task. Note: this is not our case, we have the original labels $\\{0, 1, \\dots, 9\\}$ from which we deduce the boolean value. Also, the project presentation PDF mentions:\n",
        "\n",
        "> For the [auxiliary loss], the training can in particular take advantage of the availability of the classes of the two digits in each pair, beside the Boolean value truly of interest. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtatCcAfOvEx"
      },
      "source": [
        "# Google paper \"Going deeper with convolutions\"\n",
        "\n",
        "https://arxiv.org/abs/1409.4842\n",
        "\n",
        "https://stats.stackexchange.com/questions/304699/what-is-auxiliary-loss-as-mentioned-in-pspnet-paper\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snBSBHKgOvEy"
      },
      "source": [
        "The paper from Google introduced the concept of auxiliary loss. But the focus is to improve very deep networks (they describe a 22-layer long network), whereas we don't really have deep networks for our simple task. The basic idea is to add **auxiliary classifiers connected to intermediate layers**. This is especially useful to **fight gradient vanishing and add regularization**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMYHT4_YOvEz"
      },
      "source": [
        "### Structure of extra network\n",
        "\n",
        "1. Average pooling layer\n",
        "1. 1x1 convolution for dimension reduction and relu activation\n",
        "1. fully connected and relu\n",
        "1. dropout (70%)\n",
        "1. linear layer with softmax loss as classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6eOERVwOvE0"
      },
      "source": [
        "# Draft ideas for Project 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQD_DGLDOvE0"
      },
      "source": [
        "Based on this [medium article](https://towardsdatascience.com/improve-your-neural-networks-generalization-performance-by-adding-an-unsupervised-auxiliary-loss-4d58b2dead54), we can combine the main loss with the auxiliary loss for the total loss:\n",
        "\n",
        "$$\\text{total loss} = \\text{main loss} + \\lambda \\cdot \\text{auxiliary loss}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OidAZFkJOvE1"
      },
      "source": [
        "Also, since our network is *not* deep (and can't be, because computations must be rather fast as mentionned in the project description), we should probably put the auxiliary classifier at the end of the network, and not at intermediate levels (as done in Google paper). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_Yu7RsoOvE1"
      },
      "source": [
        "Also, we must combine the main and auxiliary loss in a meaningful way:\n",
        "\n",
        "* Main loss is currently an accuracy \n",
        "* Auxiliary loss would probably be categorical cross entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4umvak0mOvE2"
      },
      "source": [
        "We should probably change the main loss to something more related to the multi-class entropy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWsFE_rfOvE2"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaNz2YYhwbXx"
      },
      "source": [
        "import torch\r\n",
        "from torchvision import datasets\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch.utils.data import TensorDataset, DataLoader\r\n",
        "\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAzBfBHS0yjp"
      },
      "source": [
        "## dataset build"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsfGSYY9QaKA",
        "outputId": "a451b6f4-461f-44d3-ca70-37dc3a88578b"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-10 13:18:28--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-03-10 13:18:28--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz.1’\n",
            "\n",
            "MNIST.tar.gz.1          [            <=>     ]  33.20M  9.75MB/s    in 4.3s    \n",
            "\n",
            "2021-03-10 13:18:33 (7.77 MB/s) - ‘MNIST.tar.gz.1’ saved [34813078]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_TIp4ACQhpr"
      },
      "source": [
        "!tar -xf MNIST.tar.gz\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adfc8yshRCUe",
        "outputId": "f9b3dc10-b9a7-4315-a43d-6511149f8aa5"
      },
      "source": [
        "!ls MNIST/processed/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test.pt  training.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6oc9g2JyCEw"
      },
      "source": [
        "######################################################################\r\n",
        "\r\n",
        "def mnist_to_pairs(nb, input, target):\r\n",
        "    input = torch.functional.F.avg_pool2d(input, kernel_size = 2)\r\n",
        "    a = torch.randperm(input.size(0))\r\n",
        "    a = a[:2 * nb].view(nb, 2)\r\n",
        "    input = torch.cat((input[a[:, 0]], input[a[:, 1]]), 1)\r\n",
        "    classes = target[a]\r\n",
        "    target = (classes[:, 0] <= classes[:, 1]).long()\r\n",
        "    return input, target, classes\r\n",
        "\r\n",
        "######################################################################\r\n",
        "\r\n",
        "def generate_pair_sets(nb):\r\n",
        "\r\n",
        "    train_set = datasets.MNIST('', train = True, download = True)\r\n",
        "    train_input = train_set.data.view(-1, 1, 28, 28).float()\r\n",
        "    train_target = train_set.targets\r\n",
        "\r\n",
        "    test_set = datasets.MNIST('', train = False, download = True)\r\n",
        "    test_input = test_set.data.view(-1, 1, 28, 28).float()\r\n",
        "    test_target = test_set.targets\r\n",
        "\r\n",
        "    return mnist_to_pairs(nb, train_input, train_target) + \\\r\n",
        "           mnist_to_pairs(nb, test_input, test_target)\r\n",
        "\r\n",
        "######################################################################"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av161kLTFpWj"
      },
      "source": [
        "train_input , train_target , train_classes , test_input , test_target , test_classes = generate_pair_sets(1000)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "XGi49cC5F1T3",
        "outputId": "2c19e984-2f45-4767-d8ea-b4ac960172b5"
      },
      "source": [
        "plt.imshow( train_input[0][0].numpy() ) \r\n",
        "plt.show()\r\n",
        "plt.imshow( train_input[0][1].numpy() ) \r\n",
        "plt.show()\r\n",
        "print(f'train shape : {train_input.shape}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "train shape : torch.Size([1000, 2, 14, 14])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImsRSpztHZ_Z"
      },
      "source": [
        "train_dataset = TensorDataset(train_input,train_target , train_classes)\r\n",
        "train_dataloader = DataLoader(train_dataset , batch_size=100)\r\n",
        "\r\n",
        "test_dataset = TensorDataset(test_input,test_target , test_classes)\r\n",
        "test_dataloader = DataLoader(test_dataset , batch_size=100)\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8P1WI8gOvE-"
      },
      "source": [
        "# Fully dense net with aux loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NDo4PotHZye"
      },
      "source": [
        "class FullyDenseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FullyDenseNet, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(2*14*14, 300)\n",
        "        self.fc2 = nn.Linear(300, 200)\n",
        "        self.fc3 = nn.Linear(200, 100)\n",
        "        self.fc4 = nn.Linear(100, 50)\n",
        "        self.fc5 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.Flatten(1)(x)\n",
        "        x = torch.relu( self.fc1(x) )\n",
        "        x = torch.relu( self.fc2(x) )\n",
        "        x = torch.relu( self.fc3(x) )\n",
        "        x = torch.relu( self.fc4(x) )\n",
        "        x = self.fc5(x)\n",
        "        return torch.sigmoid(x)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q88Hb4QOvE-"
      },
      "source": [
        "class FullyDenseNetAux(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FullyDenseNetAux, self).__init__()\n",
        "\n",
        "        # Network basis: common for all losses\n",
        "        # 14 * 14 = 196\n",
        "        self.fc1_im1 = nn.Linear(14*14, 100)\n",
        "        self.fc1_im2 = nn.Linear(14*14, 100)\n",
        "        \n",
        "        self.fc2_im1 = nn.Linear(100, 50)\n",
        "        self.fc2_im2 = nn.Linear(100, 50)\n",
        "        \n",
        "        # Auxiliary networks\n",
        "        self.fc3_im1 = nn.Linear(50, 10)\n",
        "        self.fc3_im2 = nn.Linear(50, 10)\n",
        "        \n",
        "        # Main task\n",
        "        self.fc4 = nn.Linear(2*50, 10)\n",
        "        self.fc5 = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        im1 = nn.Flatten()(x[:, 0, :, :])\n",
        "        im2 = nn.Flatten()(x[:, 1, :, :])\n",
        "        \n",
        "        im1 = torch.relu(self.fc1_im1(im1))\n",
        "        im2 = torch.relu(self.fc1_im2(im2))\n",
        "        \n",
        "        im1 = torch.relu(self.fc2_im1(im1))\n",
        "        im2 = torch.relu(self.fc2_im2(im2))\n",
        "        \n",
        "        # Main task\n",
        "        common = torch.cat((im1, im2), dim=1)\n",
        "        common = torch.relu(self.fc4(common))\n",
        "        common = self.fc5(common)\n",
        "        common = F.sigmoid(common)\n",
        "        \n",
        "        # Auxiliary networks\n",
        "        im1 = self.fc3_im1(im1)\n",
        "        im1 = F.softmax(im1)\n",
        "        \n",
        "        im2 = self.fc3_im2(im2)\n",
        "        im2 = F.softmax(im2)\n",
        "        \n",
        "        return common, im1, im2"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA3Ui4BnShQu"
      },
      "source": [
        "# Train tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y7rlAqCOvFA"
      },
      "source": [
        "def custom_loss(output, target, classes, lambda_=1.0):\n",
        "  \"\"\"\n",
        "  Custom loss for network with auxiliary losses. The total loss is a combination\n",
        "  of the loss of the main task (binary cross entropy) and the negative log likelihood\n",
        "  for the two auxiliary tasks. Importance of auxiliary losses is controlled by\n",
        "  the `lambda_` hyperparameter.\n",
        "  \"\"\"\n",
        "  main, im1, im2 = output\n",
        "\n",
        "  main_loss = F.binary_cross_entropy(main.flatten(), target)\n",
        "  aux_loss_1 = F.nll_loss(im1, classes[:, 0])\n",
        "  aux_loss_2 = F.nll_loss(im2, classes[:, 1])\n",
        "\n",
        "  return main_loss + lambda_ * (aux_loss_1 + aux_loss_2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fmv6jmZOvFA"
      },
      "source": [
        "def handle_loss(criterion):\n",
        "  \"\"\"\n",
        "  Handle the fact that the network with auxiliary loss has three-item tuple output,\n",
        "  which needs to be treated separately to compute the loss and the accuracy.\n",
        "  \"\"\"\n",
        "  if criterion is not custom_loss:\n",
        "    internal_criterion = lambda output, target, _: criterion(output.flatten(), target)\n",
        "    compute_acc = lambda output, target: (target == torch.round(output.flatten()) ).sum().item()\n",
        "  else:\n",
        "    internal_criterion = criterion\n",
        "    compute_acc = lambda output, target: (target == torch.round(output[0].flatten()) ).sum().item()\n",
        "    \n",
        "  return internal_criterion, compute_acc"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i54w5hBmHaES"
      },
      "source": [
        "def train_epoch(network_ , optimizer_ , criterion = F.binary_cross_entropy ):\n",
        "  internal_criterion, compute_acc = handle_loss(criterion)\n",
        "    \n",
        "  loss_tot = []\n",
        "  acc_tot = []\n",
        "  network_.train()\n",
        "  for batch_idx, (data, target , classes ) in enumerate(train_dataloader):\n",
        "    optimizer_.zero_grad()\n",
        "    output = network_(data)\n",
        "    loss = internal_criterion(output, target.to(torch.float32), classes)\n",
        "    loss.backward()\n",
        "    optimizer_.step()\n",
        "\n",
        "    loss_tot.append(loss.item())\n",
        "    acc_tot.append( compute_acc(output, target) )\n",
        "  \n",
        "  return torch.FloatTensor(loss_tot).mean().item() , torch.FloatTensor(acc_tot).mean().item()/100.0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe7whYlPQoLi"
      },
      "source": [
        "def test(network_ , criterion_ = F.binary_cross_entropy):\n",
        "  internal_criterion, compute_acc = handle_loss(criterion_)\n",
        "\n",
        "  network_.eval()\n",
        "  test_loss = 0\n",
        "  acc = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, target , classes in test_dataloader:\n",
        "      output = network_(data)\n",
        "      test_loss += internal_criterion(output, target.to(torch.float32), classes)\n",
        "      acc += compute_acc(output, target)\n",
        "\n",
        "  test_loss /= len(test_dataloader)\n",
        "  acc /= len(test_dataloader)\n",
        "  return test_loss , acc/100.0"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHcA1vKgHaGi"
      },
      "source": [
        "def train(network_ , optimizer_ , criterion_ = F.binary_cross_entropy ,epoch_nb = 30,   debug_ = True):\r\n",
        "\r\n",
        "  tot_train_loss = []\r\n",
        "  tot_train_acc = []\r\n",
        "  tot_test_loss = []\r\n",
        "  tot_test_acc = []\r\n",
        "\r\n",
        "\r\n",
        "  for epoch in range(epoch_nb):\r\n",
        "    train_loss , train_acc = train_epoch(network_ , optimizer_ , criterion_)\r\n",
        "    test_loss , test_acc = test(network_ , criterion_)\r\n",
        "\r\n",
        "    tot_train_loss.append(train_loss)\r\n",
        "    tot_train_acc.append(train_acc)\r\n",
        "    tot_test_loss.append(test_loss)\r\n",
        "    tot_test_acc.append(test_acc)\r\n",
        "\r\n",
        "    if(debug_):\r\n",
        "      print(epoch, f'{train_loss:.4}\\t{train_acc:.4}\\t{test_loss:.4}\\t{test_acc:.4}')\r\n",
        "\r\n",
        "  return tot_train_loss , tot_train_acc , tot_test_loss , tot_test_acc"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYg-E2UB8Flj"
      },
      "source": [
        "# stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffB574WB8IFx"
      },
      "source": [
        "def train_multiple_runs( network_class , runs = 10 , epoch = 30):\r\n",
        "  all_train_loss , all_train_acc , all_test_loss , all_test_acc = [],[],[],[]\r\n",
        "  \r\n",
        "  for i in range(runs):\r\n",
        "    n = network_class()\r\n",
        "    optimizer = optim.SGD(n.parameters(), lr=0.01, momentum=0.5)\r\n",
        "    criterion = F.binary_cross_entropy\r\n",
        "\r\n",
        "    tot_train_loss , tot_train_acc , tot_test_loss , tot_test_acc = train(n , optimizer , criterion , epoch , debug_ = False)\r\n",
        "    all_train_loss.append(tot_train_loss)\r\n",
        "    all_train_acc.append(tot_train_acc)\r\n",
        "    all_test_loss.append(tot_test_loss)\r\n",
        "    all_test_acc.append(tot_test_acc)\r\n",
        "\r\n",
        "  return all_train_loss , all_train_acc , all_test_loss , all_test_acc"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C66k1nu4HaMp"
      },
      "source": [
        "def plot_loss_acc( tot_train_loss , tot_train_acc , tot_test_loss , tot_test_acc ):\r\n",
        "  epochs = range(1, len(tot_train_loss)+1 )\r\n",
        "  plt.plot(epochs, tot_train_loss, 'g', label='Training loss')\r\n",
        "  plt.plot(epochs, tot_test_loss, 'b', label='Test loss')\r\n",
        "  plt.plot(epochs, tot_train_acc, 'r', label='Training acc')\r\n",
        "  plt.plot(epochs, tot_test_acc, 'y', label='Test acc')\r\n",
        "  plt.title('Training and Test loss/acc')\r\n",
        "  plt.xlabel('Epochs')\r\n",
        "  plt.ylabel('loss/acc')\r\n",
        "  plt.ylim((0,1))\r\n",
        "  plt.legend()\r\n",
        "  plt.show()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi4wxxDM9KWH"
      },
      "source": [
        "import numpy as np\r\n",
        "def plot_std_loss_acc(all_train_loss , all_train_acc , all_test_loss , all_test_acc):\r\n",
        "  trl_mean = np.array(all_train_loss).mean(axis = 0)\r\n",
        "  tel_mean = np.array(all_train_acc).mean(axis = 0)\r\n",
        "  tra_mean = np.array(all_test_loss).mean(axis = 0)\r\n",
        "  tea_mean = np.array(all_test_acc).mean(axis = 0)\r\n",
        "\r\n",
        "  trl_std = np.array(all_train_loss).std(axis = 0)\r\n",
        "  tel_std = np.array(all_train_acc).std(axis = 0)\r\n",
        "  tra_std = np.array(all_test_loss).std(axis = 0)\r\n",
        "  tea_std = np.array(all_test_acc).std(axis = 0)\r\n",
        "\r\n",
        "  epochs = range(1, len(tea_std)+1 )\r\n",
        "\r\n",
        "  temp = [ [trl_mean , trl_std] , [tel_mean , tel_std] , [tra_mean , tra_std] , [tea_mean , tea_std] ]\r\n",
        "\r\n",
        "  for g in temp : \r\n",
        "    plt.plot( epochs , g[0] )\r\n",
        "    plt.fill_between(epochs, g[0]-g[1], g[0]+g[1] ,alpha=0.3)\r\n",
        "\r\n",
        "  plt.ylim((-0.1,1.1))\r\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zoja7A0SNHd"
      },
      "source": [
        "# Auxiliary task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6Fwn57JOvE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fbbdaa6-e19d-4a9f-8cfd-4a08c82cb116"
      },
      "source": [
        "net = FullyDenseNet()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n",
        "tot_train_loss , tot_train_acc , tot_test_loss , tot_test_acc = train(net, optimizer, F.binary_cross_entropy)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.6525\t0.627\t0.5652\t0.703\n",
            "1 0.4963\t0.76\t0.5316\t0.728\n",
            "2 0.4133\t0.814\t0.5077\t0.745\n",
            "3 0.3569\t0.851\t0.4974\t0.747\n",
            "4 0.3052\t0.873\t0.5941\t0.734\n",
            "5 0.3377\t0.848\t0.4788\t0.76\n",
            "6 0.3085\t0.877\t1.041\t0.595\n",
            "7 0.32\t0.871\t0.5748\t0.744\n",
            "8 0.2087\t0.926\t0.6243\t0.738\n",
            "9 0.1598\t0.949\t0.6571\t0.738\n",
            "10 0.1265\t0.96\t0.7616\t0.73\n",
            "11 0.1085\t0.972\t0.7549\t0.74\n",
            "12 0.1204\t0.958\t0.6259\t0.766\n",
            "13 0.3735\t0.871\t0.484\t0.759\n",
            "14 0.1763\t0.935\t0.5144\t0.775\n",
            "15 0.07723\t0.984\t0.6357\t0.766\n",
            "16 0.05384\t0.995\t0.6335\t0.774\n",
            "17 0.04367\t0.995\t0.6612\t0.775\n",
            "18 0.03421\t0.996\t0.568\t0.79\n",
            "19 0.02069\t0.999\t0.6022\t0.801\n",
            "20 0.01305\t1.0\t0.5996\t0.793\n",
            "21 0.0084\t1.0\t0.6246\t0.798\n",
            "22 0.006985\t1.0\t0.6442\t0.801\n",
            "23 0.005928\t1.0\t0.66\t0.801\n",
            "24 0.005087\t1.0\t0.675\t0.801\n",
            "25 0.004406\t1.0\t0.684\t0.802\n",
            "26 0.003828\t1.0\t0.6927\t0.802\n",
            "27 0.003371\t1.0\t0.7002\t0.804\n",
            "28 0.003002\t1.0\t0.7064\t0.803\n",
            "29 0.002688\t1.0\t0.7131\t0.803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdLX5l2XOvE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a56b7b-038b-49e3-ff40-42eda1233c06"
      },
      "source": [
        "net = FullyDenseNetAux()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n",
        "tot_train_loss , tot_train_acc , tot_test_loss , tot_test_acc = train(net, optimizer, criterion_=custom_loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 0.2192\t0.625\t-0.2691\t0.746\n",
            "1 -0.3732\t0.775\t-0.4965\t0.768\n",
            "2 -0.6086\t0.816\t-0.5811\t0.772\n",
            "3 -0.7649\t0.842\t-0.6912\t0.79\n",
            "4 -0.878\t0.851\t-0.7378\t0.79\n",
            "5 -0.9851\t0.884\t-0.6143\t0.762\n",
            "6 -1.066\t0.901\t-0.8328\t0.795\n",
            "7 -1.079\t0.883\t-0.8267\t0.787\n",
            "8 -1.125\t0.882\t-0.7682\t0.768\n",
            "9 -1.178\t0.896\t-0.8004\t0.768\n",
            "10 -1.257\t0.94\t-0.8388\t0.798\n",
            "11 -1.34\t0.975\t-0.8851\t0.803\n",
            "12 -1.395\t0.982\t-0.8797\t0.81\n",
            "13 -1.432\t0.992\t-0.8561\t0.811\n",
            "14 -1.448\t0.991\t-0.847\t0.814\n",
            "15 -1.466\t0.994\t-0.8303\t0.813\n",
            "16 -1.476\t0.996\t-0.8159\t0.818\n",
            "17 -1.492\t0.998\t-0.7545\t0.814\n",
            "18 -1.499\t0.998\t-0.7349\t0.811\n",
            "19 -1.502\t0.997\t-0.7806\t0.827\n",
            "20 -1.517\t1.0\t-0.7193\t0.816\n",
            "21 -1.523\t1.0\t-0.7627\t0.819\n",
            "22 -1.528\t1.0\t-0.7713\t0.814\n",
            "23 -1.528\t1.0\t-0.7544\t0.822\n",
            "24 -1.538\t0.999\t-0.7401\t0.821\n",
            "25 -1.556\t1.0\t-0.7252\t0.807\n",
            "26 -1.579\t1.0\t-0.7555\t0.815\n",
            "27 -1.596\t1.0\t-0.7601\t0.813\n",
            "28 -1.611\t1.0\t-0.7514\t0.813\n",
            "29 -1.619\t1.0\t-0.7646\t0.821\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}