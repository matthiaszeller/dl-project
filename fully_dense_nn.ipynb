{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_project1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCKSRMBoHkbAGlA/7E1qkX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthiaszeller/dl-project/blob/main/fully_dense_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaNz2YYhwbXx"
      },
      "source": [
        "import torch\r\n",
        "from torchvision import datasets\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch.utils.data import TensorDataset, DataLoader\r\n",
        "\r\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsfGSYY9QaKA",
        "outputId": "1712fb52-41ad-41bf-9f8e-1122d2fe1df1"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-03 19:24:54--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-03-03 19:24:54--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz.2’\n",
            "\n",
            "MNIST.tar.gz.2          [            <=>     ]  33.20M  14.0MB/s    in 2.4s    \n",
            "\n",
            "2021-03-03 19:24:57 (14.0 MB/s) - ‘MNIST.tar.gz.2’ saved [34813078]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_TIp4ACQhpr"
      },
      "source": [
        "!tar -xf MNIST.tar.gz\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adfc8yshRCUe",
        "outputId": "f71cd49a-214b-49db-a245-f78a16429b91"
      },
      "source": [
        "!ls MNIST/processed/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test.pt  training.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6oc9g2JyCEw"
      },
      "source": [
        "######################################################################\r\n",
        "\r\n",
        "def mnist_to_pairs(nb, input, target):\r\n",
        "    input = torch.functional.F.avg_pool2d(input, kernel_size = 2)\r\n",
        "    a = torch.randperm(input.size(0))\r\n",
        "    a = a[:2 * nb].view(nb, 2)\r\n",
        "    input = torch.cat((input[a[:, 0]], input[a[:, 1]]), 1)\r\n",
        "    classes = target[a]\r\n",
        "    target = (classes[:, 0] <= classes[:, 1]).long()\r\n",
        "    return input, target, classes\r\n",
        "\r\n",
        "######################################################################\r\n",
        "\r\n",
        "def generate_pair_sets(nb):\r\n",
        "\r\n",
        "    train_set = datasets.MNIST('', train = True, download = True)\r\n",
        "    train_input = train_set.data.view(-1, 1, 28, 28).float()\r\n",
        "    train_target = train_set.targets\r\n",
        "\r\n",
        "    test_set = datasets.MNIST('', train = False, download = True)\r\n",
        "    test_input = test_set.data.view(-1, 1, 28, 28).float()\r\n",
        "    test_target = test_set.targets\r\n",
        "\r\n",
        "    return mnist_to_pairs(nb, train_input, train_target) + \\\r\n",
        "           mnist_to_pairs(nb, test_input, test_target)\r\n",
        "\r\n",
        "######################################################################"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av161kLTFpWj"
      },
      "source": [
        "train_input , train_target , train_classes , test_input , test_target , test_classes = generate_pair_sets(1000)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "XGi49cC5F1T3",
        "outputId": "408e17f4-0dd8-42c3-c7f2-26f64e19a52b"
      },
      "source": [
        "plt.imshow( train_input[0][0].numpy() ) \r\n",
        "plt.show()\r\n",
        "plt.imshow( train_input[0][1].numpy() ) \r\n",
        "plt.show()\r\n",
        "print(f'train shape : {train_input.shape}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMOUlEQVR4nO3df6zddX3H8edrLVBbGT+mIULJYBthNsQNbRRwc8aypCCh/mEWcCww3JolboAhcyVsYUv2xxaZ02wMwpAfTgIxFZUwf9ChxEyxsUCDpS1SwUGxpTiZYM0olff+OIekXGnLzvd7vj3weT6Sm3u+33M+9/2+N/d1P9/zPed7P6kqJL32/cKBbkDSMAy71AjDLjXCsEuNMOxSI+YPWezgHFILWDRkSakp/8tOdtVzebn7Bg37AhbxjiwbsqTUlLV1117v8zBeaoRhlxph2KVGdAp7kuVJHkqyJcmqvpqS1L+Jw55kHnAVcAawBDg3yZK+GpPUry4z+9uBLVX1SFXtAm4FVvTTlqS+dQn7McDje2xvHe97iSQrk6xLsu55nutQTlIXUz9BV1XXVtXSqlp6EIdMu5ykvegS9ieAY/fYXjzeJ2kGdQn7t4ETkhyf5GDgHOD2ftqS1LeJ3y5bVbuT/CnwFWAecH1VPdhbZ5J61em98VX1ReCLPfUiaYp8B53UCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUiEFXcZX+P7ZffFqn8TsX18Rjf/XP7+lUexY5s0uNMOxSIwy71AjDLjWiyyquxyb5WpKNSR5McnGfjUnqV5ez8buBS6vqviSHAvcmWVNVG3vqTVKPJp7Zq2pbVd03vv0ssImXWcVV0mzo5XX2JMcBJwNrX+a+lcBKgAUs7KOcpAl0PkGX5PXAZ4FLquqZufe7ZLM0GzqFPclBjIJ+c1Xd1k9Lkqahy9n4AJ8ENlXVx/prSdI0dJnZ3wn8AfCeJOvHH2f21JeknnVZn/0/gfTYi6Qp8h10UiMMu9QIr2fXzPqjlf/eafxn/mp5T528NjizS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjvMRVU/XkRZMvu3zovNWdai+87ef+s3nTnNmlRhh2qRGGXWqEYZca0cfyT/OS3J/kjj4akjQdfczsFzNawVXSDOu61tti4L3Adf20I2laus7sHwc+ArywtwckWZlkXZJ1z/Ncx3KSJtVlYcezgB1Vde++HueSzdJs6Lqw49lJvg/cymiBx0/30pWk3k0c9qq6rKoWV9VxwDnAV6vqvN46k9QrX2eXGtHLhTBVdTdwdx9fS9J0OLNLjTDsUiO8nn0Az55zSqfxh3/loYnH/uzppzvVJuk0/JpL/mnisX954R93qj2P+zqNf61xZpcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRniJ6wDe/Rff7DR+/b2/Nvngjpe4/veF3S7P/dcdiyYeO+9uL1HtkzO71AjDLjXCsEuNMOxSI7ou7Hh4ktVJNifZlOTUvhqT1K+uZ+M/AXy5qt6f5GBgYQ89SZqCicOe5DDgXcAFAFW1C9jVT1uS+tblMP544CnghiT3J7kuyc+9qOqSzdJs6BL2+cBbgaur6mRgJ7Bq7oNcslmaDV3CvhXYWlVrx9urGYVf0gzqsmTzduDxJCeOdy0DNvbSlaTedT0b/2fAzeMz8Y8Af9i9JUnT0CnsVbUeWNpTL5KmyHfQSY0w7FIjvJ79FXr4xrdNPPbSQz/VqfY9/3L8xGN/+JMlnWp/5x1Xdxr/mZ8cNvHYVVed06n2CR9au/8HNcSZXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRng9+yu0aMPk/wb7T3Ze2Kn2/Gcn/5u89Lc3d6r9s3qh0/i//4cPTDz2zbc/2qn27k6jX3uc2aVGGHapEYZdakTXJZs/nOTBJBuS3JJkQV+NSerXxGFPcgxwEbC0qk4C5gHd/kOgpKnpehg/H3hdkvmM1mb/QfeWJE1Dl7XengCuBB4DtgE/rqo75z7OJZul2dDlMP4IYAWjddqPBhYlOW/u41yyWZoNXQ7jTwceraqnqup54DbgtH7aktS3LmF/DDglycIkYbRk86Z+2pLUty7P2dcCq4H7gO+Mv9a1PfUlqWddl2y+Ariip14kTZHvoJMaYdilRniJ6yt09JXfPNAtTOTUB5/uNP6M3+t2ee4bvnHPxGO9RLVfzuxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXC69lfBZ75wCkTj73he92uZ3/jN9Z3Gq/Z4cwuNcKwS40w7FIj9hv2JNcn2ZFkwx77jkyyJsnD489HTLdNSV29kpn9RmD5nH2rgLuq6gTgrvG2pBm237BX1deBH83ZvQK4aXz7JuB9PfclqWeTvvR2VFVtG9/eDhy1twcmWQmsBFjAwgnLSeqq8wm6qiqg9nG/SzZLM2DSsD+Z5E0A4887+mtJ0jRMGvbbgfPHt88HvtBPO5Km5ZW89HYLcA9wYpKtST4I/B3wu0keBk4fb0uaYfs9QVdV5+7lrmU99yJpinwHndQIwy41wktcXwX+8W+vmnjsX7/5tE619/qaql51nNmlRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqE17O/ClzxK2/rMPq53vrQq5szu9QIwy41wrBLjZh0yeaPJtmc5IEkn0ty+HTblNTVpEs2rwFOqqq3AN8FLuu5L0k9m2jJ5qq6s6p2jze/BSyeQm+SetTHc/YLgS/18HUkTVGn19mTXA7sBm7ex2Ncn12aAROHPckFwFnAsvEa7S+rqq4FrgX4xRzpmgPSATJR2JMsBz4C/E5V/bTfliRNw6RLNv8zcCiwJsn6JNdMuU9JHU26ZPMnp9CLpCnyHXRSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71Ijs4x/D9l8seQr4r3085A3ADwdqx9rWfi3W/uWqeuPL3TFo2PcnybqqWmpta1u7fx7GS40w7FIjZi3s11rb2taejpl6zi5pemZtZpc0JYZdasRMhD3J8iQPJdmSZNWAdY9N8rUkG5M8mOTioWrv0cO8JPcnuWPguocnWZ1kc5JNSU4dsPaHxz/vDUluSbJgyvWuT7IjyYY99h2ZZE2Sh8efjxiw9kfHP/cHknwuyeHTqD3XAQ97knnAVcAZwBLg3CRLBiq/G7i0qpYApwAfGrD2iy4GNg1cE+ATwJer6teB3xiqhyTHABcBS6vqJGAecM6Uy94ILJ+zbxVwV1WdANw13h6q9hrgpKp6C/Bd4LIp1X6JAx524O3Alqp6pKp2AbcCK4YoXFXbquq+8e1nGf3CHzNEbYAki4H3AtcNVXNc9zDgXYwX6KyqXVX1PwO2MB94XZL5wELgB9MsVlVfB340Z/cK4Kbx7ZuA9w1Vu6rurKrd481vAYunUXuuWQj7McDje2xvZcDAvSjJccDJwNoBy36c0Tr3LwxYE+B44CnghvFTiOuSLBqicFU9AVwJPAZsA35cVXcOUXuOo6pq2/j2duCoA9ADwIXAl4YoNAthP+CSvB74LHBJVT0zUM2zgB1Vde8Q9eaYD7wVuLqqTgZ2Mr3D2JcYPzdewegPztHAoiTnDVF7b2r0+vPgr0EnuZzRU8mbh6g3C2F/Ajh2j+3F432DSHIQo6DfXFW3DVUXeCdwdpLvM3rq8p4knx6o9lZga1W9eBSzmlH4h3A68GhVPVVVzwO3AacNVHtPTyZ5E8D4844hiye5ADgL+P0a6M0usxD2bwMnJDk+ycGMTtbcPkThJGH0vHVTVX1siJovqqrLqmpxVR3H6Hv+alUNMsNV1Xbg8SQnjnctAzYOUZvR4fspSRaOf/7LODAnKG8Hzh/fPh/4wlCFkyxn9PTt7Kr66VB1qaoD/gGcyeis5PeAywes+1uMDt8eANaPP848AN//u4E7Bq75m8C68ff+eeCIAWv/DbAZ2AD8G3DIlOvdwuj8wPOMjmo+CPwSo7PwDwP/ARw5YO0tjM5Tvfg7d80QP3ffLis1YhYO4yUNwLBLjTDsUiMMu9QIwy41wrBLjTDsUiP+D9a3cPqffb8CAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "train shape : torch.Size([1000, 2, 14, 14])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNiJBAR5GnIf"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NDo4PotHZye"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "\r\n",
        "        self.fc1 = nn.Linear(2*14*14, 300)\r\n",
        "        self.fc2 = nn.Linear(300, 200)\r\n",
        "        self.fc3 = nn.Linear(200, 100)\r\n",
        "        self.fc4 = nn.Linear(100, 50)\r\n",
        "        self.fc5 = nn.Linear(50, 1)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = nn.Flatten(1)(x)\r\n",
        "        x = torch.relu( self.fc1(x) )\r\n",
        "        x = torch.relu( self.fc2(x) )\r\n",
        "        x = torch.relu( self.fc3(x) )\r\n",
        "        x = torch.relu( self.fc4(x) )\r\n",
        "        x = self.fc5(x)\r\n",
        "        return torch.sigmoid(x)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwN5E7UcHZ8c"
      },
      "source": [
        "network = Net()\r\n",
        "optimizer = optim.SGD(network.parameters(), lr=0.01,\r\n",
        "                      momentum=0.5)\r\n",
        "\r\n",
        "criterion = F.binary_cross_entropy"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImsRSpztHZ_Z"
      },
      "source": [
        "train_dataset = TensorDataset(train_input,train_target , train_classes)\r\n",
        "train_dataloader = DataLoader(train_dataset , batch_size=100)\r\n",
        "\r\n",
        "test_dataset = TensorDataset(test_input,test_target , test_classes)\r\n",
        "test_dataloader = DataLoader(test_dataset , batch_size=100)\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7waMxKoqHaCF",
        "outputId": "aae65770-c0e9-4ea0-d5a3-e477343a7fbe"
      },
      "source": [
        "for el in train_dataloader:\r\n",
        "  # image , target, classes\r\n",
        "  print(el[0].shape, el[1].shape, el[2].shape)\r\n",
        "  break"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2, 14, 14]) torch.Size([100]) torch.Size([100, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i54w5hBmHaES"
      },
      "source": [
        "def train(epoch_nb):\r\n",
        "  network.train()\r\n",
        "  for batch_idx, (data, target , classes ) in enumerate(train_dataloader):\r\n",
        "    optimizer.zero_grad()\r\n",
        "    output = network(data).flatten()\r\n",
        "    loss = criterion(output, target.to(torch.float32))\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "    if batch_idx % 1 == 0:\r\n",
        "      print(f'Train Epoch: {epoch_nb} [{batch_idx}/{10}]\\tLoss: {loss.item():.6f}')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe7whYlPQoLi"
      },
      "source": [
        "def test():\r\n",
        "  network.eval()\r\n",
        "  test_loss = 0\r\n",
        "  correct = 0\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "    for data, target , classes in test_dataloader:\r\n",
        "      output = network(data)\r\n",
        "      test_loss += criterion(output.flatten(), target.to(torch.float32)).item()\r\n",
        "\r\n",
        "  test_loss /= len(test_dataloader.dataset)\r\n",
        "  print(f'\\nTest set: Avg. loss: {test_loss:.4f}, Accuracy: {404}/{404} ({404:.0f}%)\\n')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VmLfgm_R1WR",
        "outputId": "b090be30-879b-4b12-8d6c-a39173ad3e09"
      },
      "source": [
        "train(0)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/10]\tLoss: 0.722753\n",
            "Train Epoch: 0 [1/10]\tLoss: 0.646707\n",
            "Train Epoch: 0 [2/10]\tLoss: 0.687954\n",
            "Train Epoch: 0 [3/10]\tLoss: 0.666599\n",
            "Train Epoch: 0 [4/10]\tLoss: 0.712706\n",
            "Train Epoch: 0 [5/10]\tLoss: 0.654952\n",
            "Train Epoch: 0 [6/10]\tLoss: 0.633044\n",
            "Train Epoch: 0 [7/10]\tLoss: 0.619216\n",
            "Train Epoch: 0 [8/10]\tLoss: 0.560704\n",
            "Train Epoch: 0 [9/10]\tLoss: 0.614066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHcA1vKgHaGi",
        "outputId": "7558a6f6-f5b0-48f5-a5db-0fcbb7cbe779"
      },
      "source": [
        "test()\r\n",
        "for epoch in range(25):\r\n",
        "  train(epoch)\r\n",
        "  test()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 0.0057, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 0 [0/10]\tLoss: 0.558873\n",
            "Train Epoch: 0 [1/10]\tLoss: 0.549951\n",
            "Train Epoch: 0 [2/10]\tLoss: 0.508659\n",
            "Train Epoch: 0 [3/10]\tLoss: 0.574624\n",
            "Train Epoch: 0 [4/10]\tLoss: 0.556352\n",
            "Train Epoch: 0 [5/10]\tLoss: 0.501542\n",
            "Train Epoch: 0 [6/10]\tLoss: 0.544714\n",
            "Train Epoch: 0 [7/10]\tLoss: 0.463029\n",
            "Train Epoch: 0 [8/10]\tLoss: 0.444488\n",
            "Train Epoch: 0 [9/10]\tLoss: 0.467870\n",
            "\n",
            "Test set: Avg. loss: 0.0052, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 1 [0/10]\tLoss: 0.510390\n",
            "Train Epoch: 1 [1/10]\tLoss: 0.456780\n",
            "Train Epoch: 1 [2/10]\tLoss: 0.432727\n",
            "Train Epoch: 1 [3/10]\tLoss: 0.525652\n",
            "Train Epoch: 1 [4/10]\tLoss: 0.466259\n",
            "Train Epoch: 1 [5/10]\tLoss: 0.425206\n",
            "Train Epoch: 1 [6/10]\tLoss: 0.453475\n",
            "Train Epoch: 1 [7/10]\tLoss: 0.395419\n",
            "Train Epoch: 1 [8/10]\tLoss: 0.346428\n",
            "Train Epoch: 1 [9/10]\tLoss: 0.419485\n",
            "\n",
            "Test set: Avg. loss: 0.0061, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 2 [0/10]\tLoss: 0.526765\n",
            "Train Epoch: 2 [1/10]\tLoss: 0.531911\n",
            "Train Epoch: 2 [2/10]\tLoss: 0.406121\n",
            "Train Epoch: 2 [3/10]\tLoss: 0.478134\n",
            "Train Epoch: 2 [4/10]\tLoss: 0.412031\n",
            "Train Epoch: 2 [5/10]\tLoss: 0.367465\n",
            "Train Epoch: 2 [6/10]\tLoss: 0.403151\n",
            "Train Epoch: 2 [7/10]\tLoss: 0.370657\n",
            "Train Epoch: 2 [8/10]\tLoss: 0.305640\n",
            "Train Epoch: 2 [9/10]\tLoss: 0.391146\n",
            "\n",
            "Test set: Avg. loss: 0.0059, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 3 [0/10]\tLoss: 0.437423\n",
            "Train Epoch: 3 [1/10]\tLoss: 0.356441\n",
            "Train Epoch: 3 [2/10]\tLoss: 0.333355\n",
            "Train Epoch: 3 [3/10]\tLoss: 0.595644\n",
            "Train Epoch: 3 [4/10]\tLoss: 0.629333\n",
            "Train Epoch: 3 [5/10]\tLoss: 0.405374\n",
            "Train Epoch: 3 [6/10]\tLoss: 0.413374\n",
            "Train Epoch: 3 [7/10]\tLoss: 0.355527\n",
            "Train Epoch: 3 [8/10]\tLoss: 0.325709\n",
            "Train Epoch: 3 [9/10]\tLoss: 0.342248\n",
            "\n",
            "Test set: Avg. loss: 0.0048, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 4 [0/10]\tLoss: 0.325090\n",
            "Train Epoch: 4 [1/10]\tLoss: 0.337642\n",
            "Train Epoch: 4 [2/10]\tLoss: 0.392289\n",
            "Train Epoch: 4 [3/10]\tLoss: 0.557763\n",
            "Train Epoch: 4 [4/10]\tLoss: 0.365030\n",
            "Train Epoch: 4 [5/10]\tLoss: 0.345299\n",
            "Train Epoch: 4 [6/10]\tLoss: 0.386752\n",
            "Train Epoch: 4 [7/10]\tLoss: 0.301371\n",
            "Train Epoch: 4 [8/10]\tLoss: 0.278505\n",
            "Train Epoch: 4 [9/10]\tLoss: 0.295318\n",
            "\n",
            "Test set: Avg. loss: 0.0049, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 5 [0/10]\tLoss: 0.274671\n",
            "Train Epoch: 5 [1/10]\tLoss: 0.278212\n",
            "Train Epoch: 5 [2/10]\tLoss: 0.258988\n",
            "Train Epoch: 5 [3/10]\tLoss: 0.342193\n",
            "Train Epoch: 5 [4/10]\tLoss: 0.295845\n",
            "Train Epoch: 5 [5/10]\tLoss: 0.577574\n",
            "Train Epoch: 5 [6/10]\tLoss: 0.572103\n",
            "Train Epoch: 5 [7/10]\tLoss: 0.302694\n",
            "Train Epoch: 5 [8/10]\tLoss: 0.332559\n",
            "Train Epoch: 5 [9/10]\tLoss: 0.326588\n",
            "\n",
            "Test set: Avg. loss: 0.0048, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 6 [0/10]\tLoss: 0.291559\n",
            "Train Epoch: 6 [1/10]\tLoss: 0.334932\n",
            "Train Epoch: 6 [2/10]\tLoss: 0.220782\n",
            "Train Epoch: 6 [3/10]\tLoss: 0.346360\n",
            "Train Epoch: 6 [4/10]\tLoss: 0.389658\n",
            "Train Epoch: 6 [5/10]\tLoss: 0.318037\n",
            "Train Epoch: 6 [6/10]\tLoss: 0.298866\n",
            "Train Epoch: 6 [7/10]\tLoss: 0.635915\n",
            "Train Epoch: 6 [8/10]\tLoss: 0.291464\n",
            "Train Epoch: 6 [9/10]\tLoss: 0.409641\n",
            "\n",
            "Test set: Avg. loss: 0.0045, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 7 [0/10]\tLoss: 0.235123\n",
            "Train Epoch: 7 [1/10]\tLoss: 0.362610\n",
            "Train Epoch: 7 [2/10]\tLoss: 0.212474\n",
            "Train Epoch: 7 [3/10]\tLoss: 0.363113\n",
            "Train Epoch: 7 [4/10]\tLoss: 0.201224\n",
            "Train Epoch: 7 [5/10]\tLoss: 0.242564\n",
            "Train Epoch: 7 [6/10]\tLoss: 0.274397\n",
            "Train Epoch: 7 [7/10]\tLoss: 0.223546\n",
            "Train Epoch: 7 [8/10]\tLoss: 0.213303\n",
            "Train Epoch: 7 [9/10]\tLoss: 0.336529\n",
            "\n",
            "Test set: Avg. loss: 0.0045, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 8 [0/10]\tLoss: 0.200028\n",
            "Train Epoch: 8 [1/10]\tLoss: 0.305164\n",
            "Train Epoch: 8 [2/10]\tLoss: 0.152980\n",
            "Train Epoch: 8 [3/10]\tLoss: 0.305981\n",
            "Train Epoch: 8 [4/10]\tLoss: 0.156842\n",
            "Train Epoch: 8 [5/10]\tLoss: 0.174710\n",
            "Train Epoch: 8 [6/10]\tLoss: 0.189076\n",
            "Train Epoch: 8 [7/10]\tLoss: 0.160523\n",
            "Train Epoch: 8 [8/10]\tLoss: 0.140379\n",
            "Train Epoch: 8 [9/10]\tLoss: 0.193621\n",
            "\n",
            "Test set: Avg. loss: 0.0049, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 9 [0/10]\tLoss: 0.174269\n",
            "Train Epoch: 9 [1/10]\tLoss: 0.234761\n",
            "Train Epoch: 9 [2/10]\tLoss: 0.116973\n",
            "Train Epoch: 9 [3/10]\tLoss: 0.268278\n",
            "Train Epoch: 9 [4/10]\tLoss: 0.118128\n",
            "Train Epoch: 9 [5/10]\tLoss: 0.146335\n",
            "Train Epoch: 9 [6/10]\tLoss: 0.139854\n",
            "Train Epoch: 9 [7/10]\tLoss: 0.119858\n",
            "Train Epoch: 9 [8/10]\tLoss: 0.114453\n",
            "Train Epoch: 9 [9/10]\tLoss: 0.124736\n",
            "\n",
            "Test set: Avg. loss: 0.0057, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 10 [0/10]\tLoss: 0.157437\n",
            "Train Epoch: 10 [1/10]\tLoss: 0.132125\n",
            "Train Epoch: 10 [2/10]\tLoss: 0.181862\n",
            "Train Epoch: 10 [3/10]\tLoss: 0.313652\n",
            "Train Epoch: 10 [4/10]\tLoss: 0.110596\n",
            "Train Epoch: 10 [5/10]\tLoss: 0.119364\n",
            "Train Epoch: 10 [6/10]\tLoss: 0.112224\n",
            "Train Epoch: 10 [7/10]\tLoss: 0.106235\n",
            "Train Epoch: 10 [8/10]\tLoss: 0.075642\n",
            "Train Epoch: 10 [9/10]\tLoss: 0.089806\n",
            "\n",
            "Test set: Avg. loss: 0.0060, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 11 [0/10]\tLoss: 0.106415\n",
            "Train Epoch: 11 [1/10]\tLoss: 0.090264\n",
            "Train Epoch: 11 [2/10]\tLoss: 0.270485\n",
            "Train Epoch: 11 [3/10]\tLoss: 0.240296\n",
            "Train Epoch: 11 [4/10]\tLoss: 0.108546\n",
            "Train Epoch: 11 [5/10]\tLoss: 0.147358\n",
            "Train Epoch: 11 [6/10]\tLoss: 0.090543\n",
            "Train Epoch: 11 [7/10]\tLoss: 0.104657\n",
            "Train Epoch: 11 [8/10]\tLoss: 0.061342\n",
            "Train Epoch: 11 [9/10]\tLoss: 0.084042\n",
            "\n",
            "Test set: Avg. loss: 0.0059, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 12 [0/10]\tLoss: 0.075863\n",
            "Train Epoch: 12 [1/10]\tLoss: 0.104666\n",
            "Train Epoch: 12 [2/10]\tLoss: 0.130982\n",
            "Train Epoch: 12 [3/10]\tLoss: 0.158028\n",
            "Train Epoch: 12 [4/10]\tLoss: 0.369259\n",
            "Train Epoch: 12 [5/10]\tLoss: 0.221062\n",
            "Train Epoch: 12 [6/10]\tLoss: 0.075335\n",
            "Train Epoch: 12 [7/10]\tLoss: 0.129724\n",
            "Train Epoch: 12 [8/10]\tLoss: 0.069984\n",
            "Train Epoch: 12 [9/10]\tLoss: 0.086762\n",
            "\n",
            "Test set: Avg. loss: 0.0057, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 13 [0/10]\tLoss: 0.073581\n",
            "Train Epoch: 13 [1/10]\tLoss: 0.095779\n",
            "Train Epoch: 13 [2/10]\tLoss: 0.060225\n",
            "Train Epoch: 13 [3/10]\tLoss: 0.189605\n",
            "Train Epoch: 13 [4/10]\tLoss: 0.089841\n",
            "Train Epoch: 13 [5/10]\tLoss: 0.221867\n",
            "Train Epoch: 13 [6/10]\tLoss: 0.242173\n",
            "Train Epoch: 13 [7/10]\tLoss: 0.080484\n",
            "Train Epoch: 13 [8/10]\tLoss: 0.095755\n",
            "Train Epoch: 13 [9/10]\tLoss: 0.067955\n",
            "\n",
            "Test set: Avg. loss: 0.0053, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 14 [0/10]\tLoss: 0.070577\n",
            "Train Epoch: 14 [1/10]\tLoss: 0.077986\n",
            "Train Epoch: 14 [2/10]\tLoss: 0.042443\n",
            "Train Epoch: 14 [3/10]\tLoss: 0.082633\n",
            "Train Epoch: 14 [4/10]\tLoss: 0.044684\n",
            "Train Epoch: 14 [5/10]\tLoss: 0.056241\n",
            "Train Epoch: 14 [6/10]\tLoss: 0.050766\n",
            "Train Epoch: 14 [7/10]\tLoss: 0.083493\n",
            "Train Epoch: 14 [8/10]\tLoss: 0.037106\n",
            "Train Epoch: 14 [9/10]\tLoss: 0.061650\n",
            "\n",
            "Test set: Avg. loss: 0.0058, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 15 [0/10]\tLoss: 0.027754\n",
            "Train Epoch: 15 [1/10]\tLoss: 0.030757\n",
            "Train Epoch: 15 [2/10]\tLoss: 0.025668\n",
            "Train Epoch: 15 [3/10]\tLoss: 0.065704\n",
            "Train Epoch: 15 [4/10]\tLoss: 0.026362\n",
            "Train Epoch: 15 [5/10]\tLoss: 0.029848\n",
            "Train Epoch: 15 [6/10]\tLoss: 0.029751\n",
            "Train Epoch: 15 [7/10]\tLoss: 0.031323\n",
            "Train Epoch: 15 [8/10]\tLoss: 0.043750\n",
            "Train Epoch: 15 [9/10]\tLoss: 0.020910\n",
            "\n",
            "Test set: Avg. loss: 0.0074, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 16 [0/10]\tLoss: 0.043199\n",
            "Train Epoch: 16 [1/10]\tLoss: 0.024349\n",
            "Train Epoch: 16 [2/10]\tLoss: 0.020047\n",
            "Train Epoch: 16 [3/10]\tLoss: 0.049195\n",
            "Train Epoch: 16 [4/10]\tLoss: 0.022644\n",
            "Train Epoch: 16 [5/10]\tLoss: 0.021423\n",
            "Train Epoch: 16 [6/10]\tLoss: 0.022717\n",
            "Train Epoch: 16 [7/10]\tLoss: 0.022679\n",
            "Train Epoch: 16 [8/10]\tLoss: 0.019169\n",
            "Train Epoch: 16 [9/10]\tLoss: 0.018411\n",
            "\n",
            "Test set: Avg. loss: 0.0063, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 17 [0/10]\tLoss: 0.012045\n",
            "Train Epoch: 17 [1/10]\tLoss: 0.041351\n",
            "Train Epoch: 17 [2/10]\tLoss: 0.014577\n",
            "Train Epoch: 17 [3/10]\tLoss: 0.037099\n",
            "Train Epoch: 17 [4/10]\tLoss: 0.030121\n",
            "Train Epoch: 17 [5/10]\tLoss: 0.016033\n",
            "Train Epoch: 17 [6/10]\tLoss: 0.018230\n",
            "Train Epoch: 17 [7/10]\tLoss: 0.020281\n",
            "Train Epoch: 17 [8/10]\tLoss: 0.012956\n",
            "Train Epoch: 17 [9/10]\tLoss: 0.015850\n",
            "\n",
            "Test set: Avg. loss: 0.0060, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 18 [0/10]\tLoss: 0.011229\n",
            "Train Epoch: 18 [1/10]\tLoss: 0.017504\n",
            "Train Epoch: 18 [2/10]\tLoss: 0.020285\n",
            "Train Epoch: 18 [3/10]\tLoss: 0.022563\n",
            "Train Epoch: 18 [4/10]\tLoss: 0.023347\n",
            "Train Epoch: 18 [5/10]\tLoss: 0.012053\n",
            "Train Epoch: 18 [6/10]\tLoss: 0.009023\n",
            "Train Epoch: 18 [7/10]\tLoss: 0.015057\n",
            "Train Epoch: 18 [8/10]\tLoss: 0.009948\n",
            "Train Epoch: 18 [9/10]\tLoss: 0.009940\n",
            "\n",
            "Test set: Avg. loss: 0.0062, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 19 [0/10]\tLoss: 0.009000\n",
            "Train Epoch: 19 [1/10]\tLoss: 0.011388\n",
            "Train Epoch: 19 [2/10]\tLoss: 0.009585\n",
            "Train Epoch: 19 [3/10]\tLoss: 0.018727\n",
            "Train Epoch: 19 [4/10]\tLoss: 0.009015\n",
            "Train Epoch: 19 [5/10]\tLoss: 0.010122\n",
            "Train Epoch: 19 [6/10]\tLoss: 0.008472\n",
            "Train Epoch: 19 [7/10]\tLoss: 0.011620\n",
            "Train Epoch: 19 [8/10]\tLoss: 0.007151\n",
            "Train Epoch: 19 [9/10]\tLoss: 0.008080\n",
            "\n",
            "Test set: Avg. loss: 0.0066, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 20 [0/10]\tLoss: 0.006911\n",
            "Train Epoch: 20 [1/10]\tLoss: 0.010632\n",
            "Train Epoch: 20 [2/10]\tLoss: 0.007347\n",
            "Train Epoch: 20 [3/10]\tLoss: 0.013452\n",
            "Train Epoch: 20 [4/10]\tLoss: 0.007118\n",
            "Train Epoch: 20 [5/10]\tLoss: 0.007566\n",
            "Train Epoch: 20 [6/10]\tLoss: 0.006454\n",
            "Train Epoch: 20 [7/10]\tLoss: 0.009773\n",
            "Train Epoch: 20 [8/10]\tLoss: 0.005981\n",
            "Train Epoch: 20 [9/10]\tLoss: 0.006890\n",
            "\n",
            "Test set: Avg. loss: 0.0067, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 21 [0/10]\tLoss: 0.005792\n",
            "Train Epoch: 21 [1/10]\tLoss: 0.009130\n",
            "Train Epoch: 21 [2/10]\tLoss: 0.006547\n",
            "Train Epoch: 21 [3/10]\tLoss: 0.011494\n",
            "Train Epoch: 21 [4/10]\tLoss: 0.005956\n",
            "Train Epoch: 21 [5/10]\tLoss: 0.006509\n",
            "Train Epoch: 21 [6/10]\tLoss: 0.005596\n",
            "Train Epoch: 21 [7/10]\tLoss: 0.008616\n",
            "Train Epoch: 21 [8/10]\tLoss: 0.005258\n",
            "Train Epoch: 21 [9/10]\tLoss: 0.006025\n",
            "\n",
            "Test set: Avg. loss: 0.0069, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 22 [0/10]\tLoss: 0.005051\n",
            "Train Epoch: 22 [1/10]\tLoss: 0.007969\n",
            "Train Epoch: 22 [2/10]\tLoss: 0.005851\n",
            "Train Epoch: 22 [3/10]\tLoss: 0.009871\n",
            "Train Epoch: 22 [4/10]\tLoss: 0.004926\n",
            "Train Epoch: 22 [5/10]\tLoss: 0.005524\n",
            "Train Epoch: 22 [6/10]\tLoss: 0.004920\n",
            "Train Epoch: 22 [7/10]\tLoss: 0.007625\n",
            "Train Epoch: 22 [8/10]\tLoss: 0.004790\n",
            "Train Epoch: 22 [9/10]\tLoss: 0.005401\n",
            "\n",
            "Test set: Avg. loss: 0.0070, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 23 [0/10]\tLoss: 0.004449\n",
            "Train Epoch: 23 [1/10]\tLoss: 0.006898\n",
            "Train Epoch: 23 [2/10]\tLoss: 0.005334\n",
            "Train Epoch: 23 [3/10]\tLoss: 0.008654\n",
            "Train Epoch: 23 [4/10]\tLoss: 0.004161\n",
            "Train Epoch: 23 [5/10]\tLoss: 0.004821\n",
            "Train Epoch: 23 [6/10]\tLoss: 0.004236\n",
            "Train Epoch: 23 [7/10]\tLoss: 0.006764\n",
            "Train Epoch: 23 [8/10]\tLoss: 0.004439\n",
            "Train Epoch: 23 [9/10]\tLoss: 0.004917\n",
            "\n",
            "Test set: Avg. loss: 0.0070, Accuracy: 404/404 (404%)\n",
            "\n",
            "Train Epoch: 24 [0/10]\tLoss: 0.003980\n",
            "Train Epoch: 24 [1/10]\tLoss: 0.005960\n",
            "Train Epoch: 24 [2/10]\tLoss: 0.004714\n",
            "Train Epoch: 24 [3/10]\tLoss: 0.007705\n",
            "Train Epoch: 24 [4/10]\tLoss: 0.003620\n",
            "Train Epoch: 24 [5/10]\tLoss: 0.004314\n",
            "Train Epoch: 24 [6/10]\tLoss: 0.003726\n",
            "Train Epoch: 24 [7/10]\tLoss: 0.006042\n",
            "Train Epoch: 24 [8/10]\tLoss: 0.004120\n",
            "Train Epoch: 24 [9/10]\tLoss: 0.004532\n",
            "\n",
            "Test set: Avg. loss: 0.0071, Accuracy: 404/404 (404%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjO_IgLPHaIe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C66k1nu4HaMp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1AxFKKCHaQK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}